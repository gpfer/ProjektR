{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "lighting_assessment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "muJidOVNtKpn"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.optim as optim"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeebtLJvtKpz"
      },
      "source": [
        "Metoda za dobavljanje slika"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ya6ROpbtKpz"
      },
      "source": [
        "def get_images(root, last_image_index):\n",
        "    train_images = []\n",
        "    test_images = []\n",
        "    \n",
        "    for i in range(1, last_image_index):\n",
        "      name = str(i) + \".JPG\"\n",
        "      img = Image.open(root + '/' + name)\n",
        "      basewidth = 128\n",
        "      wpercent = (basewidth/float(img.size[0]))\n",
        "      hsize = int((float(img.size[1])*float(wpercent)))\n",
        "      img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
        "      a = np.asarray(img, dtype='float32')\n",
        "      a = a * 256\n",
        "      a = a - 2048\n",
        "      a[a<0] = 0\n",
        "      a /= 65536\n",
        "      a = torch.from_numpy(a)\n",
        "      a = a.transpose(0, 2)\n",
        "      if i < int(0.8*last_image_index):\n",
        "        train_images.append(a)\n",
        "      else:\n",
        "        test_images.append(a)\n",
        "        \n",
        "    return train_images, test_images"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUk69D8StKpz",
        "outputId": "8b47651b-a06b-4826-a759-3993f0ac09ee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_images, test_images = get_images(\"/content/drive/My Drive/JPG\", 1708)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ_BiIc6tKp0"
      },
      "source": [
        "Priprema slika za neuronsku mrežu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AotsDO9tKp0",
        "outputId": "26ca09d6-6ecc-472d-cf37-e8debac8353d"
      },
      "source": [
        "def get_labels(root):\n",
        "    labels = []\n",
        "    \n",
        "    labels_file = open(root, 'r')\n",
        "    lines = labels_file.readlines()\n",
        "    \n",
        "    for line in lines:\n",
        "        rgb = []\n",
        "        line = line.split(\" \")\n",
        "        rgb.append(float(line[0]))\n",
        "        rgb.append(float(line[1]))\n",
        "        rgb.append(float(line[2]))\n",
        "        \n",
        "        labels.append(rgb)\n",
        "        \n",
        "    return labels\n",
        "\n",
        "train_images = torch.stack(train_images)\n",
        "test_images = torch.stack(test_images)\n",
        "\n",
        "labels = torch.FloatTensor(get_labels(\"/content/drive/My Drive/dataset/cube+_gt.txt\"))\n",
        "\n",
        "train_labels = labels[:int(0.8*len(labels))]\n",
        "test_labels = labels[int(0.8*len(labels)):]\n",
        "print(train_labels.shape, test_labels.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1365, 3]) torch.Size([342, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxwYqPJDtKp1",
        "outputId": "6fe05e3f-4ced-4448-ab68-b853e39f9717"
      },
      "source": [
        "train_images = train_images.type(torch.FloatTensor)\n",
        "test_images = test_images.type(torch.FloatTensor)\n",
        "\n",
        "train_labels = train_labels.type(torch.FloatTensor)\n",
        "test_labels = test_labels.type(torch.FloatTensor)\n",
        "\n",
        "print(train_images.shape, train_labels.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1365, 3, 128, 85]) torch.Size([1365, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O07lXqgtKp1"
      },
      "source": [
        "train_dataset = TensorDataset(train_images, train_labels)\n",
        "test_dataset = TensorDataset(test_images, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMKIgDtutKp1"
      },
      "source": [
        "Definiranje klase neuronske mreže"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "patT7dMitKp2"
      },
      "source": [
        " class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(16, 32, kernel_size=5)\n",
        "    self.conv3 = nn.Conv2d(32, 64, kernel_size=5)\n",
        "\n",
        "    self.fc1 = nn.Linear(5376, 1000)\n",
        "    self.fc2 = nn.Linear(1000, 200)\n",
        "    self.fc3 = nn.Linear(200, 3)\n",
        "\n",
        "    self.batch = nn.BatchNorm1d(1000)\n",
        "    \n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = x.view(-1, 5376)\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.batch(x)\n",
        "\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.fc3(x)\n",
        "    x = self.relu(x)\n",
        "    \n",
        "    return torch.tanh(x)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klAWcrEWtKp2"
      },
      "source": [
        "n_epochs = 10\n",
        "learning_rate = 0.00005\n",
        "device = 'cpu'"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb4NDI1itKp2"
      },
      "source": [
        "Metoda za korak treniranja"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ6nTZQMtKp2"
      },
      "source": [
        "def train_step(network, train_data, epoch, device):\n",
        "  losses = []\n",
        "  counter = []\n",
        "\n",
        "  network.train()\n",
        "  for idx, (data, target) in enumerate(train_data):\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    network.zero_grad()\n",
        "    output = network(data)\n",
        "    loss = F.mse_loss(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if idx % 5 == 0:\n",
        "      print('Train Epoch: {:2d}, ({:2.0f}%), Loss: {:.5f}'.format(\n",
        "          epoch, 100*idx*64/len(train_data.dataset), loss\n",
        "      ))\n",
        "      losses.append(loss)\n",
        "      counter.append(idx*64 + (epoch-1)*len(train_data.dataset))\n",
        "\n",
        "  return losses, counter"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9SzeI5GtKp3"
      },
      "source": [
        "Metoda za testiranje"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2Xg7jzdtKp3"
      },
      "source": [
        "def test(network, test_data, device):\n",
        "  network.eval()\n",
        "\n",
        "  loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_data:\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      output = network(data)\n",
        "      loss += F.mse_loss(output, target, reduction=\"sum\").item()\n",
        "\n",
        "  loss /= len(test_data.dataset)\n",
        "  accuracy = 100 * correct / len(test_data.dataset)\n",
        "\n",
        "  return loss, accuracy"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPrS-l-vtKp3"
      },
      "source": [
        "def train(network, train_data, test_data, device='cpu'):\n",
        "  test_loss = []\n",
        "  test_acc = []\n",
        "  train_loss = []\n",
        "  counter = []\n",
        "\n",
        "  # testiramo pocetni model\n",
        "  loss_t, acc_t = test(network, test_data, device)\n",
        "  test_loss.append(loss_t)\n",
        "  test_acc.append(acc_t)\n",
        "\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "    # korak i testsad \n",
        "    loss, cnt = train_step(network, train_data, epoch, device)\n",
        "    loss_t, acc_t = test(network, test_data, device)\n",
        "\n",
        "    test_loss.append(loss_t)\n",
        "    test_acc.append(acc_t)\n",
        "    train_loss.append(loss)\n",
        "    counter.append(cnt)\n",
        "\n",
        "  return test_loss, test_acc, train_loss, counter\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSXUK4nMtKp4"
      },
      "source": [
        "Kreiranje i treniranje mreže"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B9Z-qK4tKp4",
        "outputId": "7c09ee26-b9c8-4ca6-bd84-f8083270a30f"
      },
      "source": [
        "network = Net()\n",
        "\n",
        "optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n",
        "test_loss, test_acc, train_loss, counter = train(network, train_loader, test_loader, device)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch:  1, ( 0%), Loss: 0.09981\n",
            "Train Epoch:  1, (23%), Loss: 0.05669\n",
            "Train Epoch:  1, (47%), Loss: 0.04511\n",
            "Train Epoch:  1, (70%), Loss: 0.03817\n",
            "Train Epoch:  1, (94%), Loss: 0.02610\n",
            "Train Epoch:  2, ( 0%), Loss: 0.02289\n",
            "Train Epoch:  2, (23%), Loss: 0.01905\n",
            "Train Epoch:  2, (47%), Loss: 0.01938\n",
            "Train Epoch:  2, (70%), Loss: 0.01590\n",
            "Train Epoch:  2, (94%), Loss: 0.01394\n",
            "Train Epoch:  3, ( 0%), Loss: 0.01060\n",
            "Train Epoch:  3, (23%), Loss: 0.00795\n",
            "Train Epoch:  3, (47%), Loss: 0.00633\n",
            "Train Epoch:  3, (70%), Loss: 0.00617\n",
            "Train Epoch:  3, (94%), Loss: 0.00761\n",
            "Train Epoch:  4, ( 0%), Loss: 0.00538\n",
            "Train Epoch:  4, (23%), Loss: 0.00325\n",
            "Train Epoch:  4, (47%), Loss: 0.00377\n",
            "Train Epoch:  4, (70%), Loss: 0.00485\n",
            "Train Epoch:  4, (94%), Loss: 0.00387\n",
            "Train Epoch:  5, ( 0%), Loss: 0.00391\n",
            "Train Epoch:  5, (23%), Loss: 0.00392\n",
            "Train Epoch:  5, (47%), Loss: 0.00184\n",
            "Train Epoch:  5, (70%), Loss: 0.00278\n",
            "Train Epoch:  5, (94%), Loss: 0.00243\n",
            "Train Epoch:  6, ( 0%), Loss: 0.00216\n",
            "Train Epoch:  6, (23%), Loss: 0.00307\n",
            "Train Epoch:  6, (47%), Loss: 0.00221\n",
            "Train Epoch:  6, (70%), Loss: 0.00175\n",
            "Train Epoch:  6, (94%), Loss: 0.00263\n",
            "Train Epoch:  7, ( 0%), Loss: 0.00137\n",
            "Train Epoch:  7, (23%), Loss: 0.00165\n",
            "Train Epoch:  7, (47%), Loss: 0.00189\n",
            "Train Epoch:  7, (70%), Loss: 0.00148\n",
            "Train Epoch:  7, (94%), Loss: 0.00153\n",
            "Train Epoch:  8, ( 0%), Loss: 0.00235\n",
            "Train Epoch:  8, (23%), Loss: 0.00185\n",
            "Train Epoch:  8, (47%), Loss: 0.00181\n",
            "Train Epoch:  8, (70%), Loss: 0.00253\n",
            "Train Epoch:  8, (94%), Loss: 0.00221\n",
            "Train Epoch:  9, ( 0%), Loss: 0.00113\n",
            "Train Epoch:  9, (23%), Loss: 0.00188\n",
            "Train Epoch:  9, (47%), Loss: 0.00141\n",
            "Train Epoch:  9, (70%), Loss: 0.00124\n",
            "Train Epoch:  9, (94%), Loss: 0.00148\n",
            "Train Epoch: 10, ( 0%), Loss: 0.00149\n",
            "Train Epoch: 10, (23%), Loss: 0.00089\n",
            "Train Epoch: 10, (47%), Loss: 0.00129\n",
            "Train Epoch: 10, (70%), Loss: 0.00115\n",
            "Train Epoch: 10, (94%), Loss: 0.00138\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}